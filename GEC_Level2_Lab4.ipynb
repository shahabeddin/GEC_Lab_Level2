{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEC Data Science Program\n",
    "## Level 2: Lab4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"toc\"><ul class=\"toc\"><li><a href=\"#GEC-Data-Science-Program\">I. GEC Data Science Program</a><a class=\"anchor-link\" href=\"#GEC-Data-Science-Program\">¶</a></li><ul class=\"toc\"><li><a href=\"#Level-2%3A-Lab4\">I. Level 2: Lab4</a><a class=\"anchor-link\" href=\"#Level-2:-Lab4\">¶</a></li><ul class=\"toc\"><ul class=\"toc\"><li><a href=\"#Momentum\">I. Momentum</a><a class=\"anchor-link\" href=\"#Momentum\">¶</a></li></ul><li><a href=\"#Convolution2d\">I. Convolution2d</a><a class=\"anchor-link\" href=\"#Convolution2d\">¶</a></li><ul class=\"toc\"><li><a href=\"#Let's-look-at-a-single-Convolution-layer\">I. Let's look at a single Convolution layer</a><a class=\"anchor-link\" href=\"#Let's-look-at-a-single-Convolution-layer\">¶</a></li><li><a href=\"#Q%3A-what's-the-output-size%3F\">II. Q: what's the output size?</a><a class=\"anchor-link\" href=\"#Q:-what's-the-output-size?\">¶</a></li><li><a href=\"#Q%3A-Change-padding-parameter-to-'same'.-What's-the-output-size-now%3F\">III. Q: Change padding parameter to 'same'. What's the output size now?</a><a class=\"anchor-link\" href=\"#Q:-Change-padding-parameter-to-'same'.-What's-the-output-size-now?\">¶</a></li><li><a href=\"#Q%3A-Change-number-of-filters--to-10.-What's-the-output-size-now%3F\">IV. Q: Change number of filters  to 10. What's the output size now?</a><a class=\"anchor-link\" href=\"#Q:-Change-number-of-filters--to-10.-What's-the-output-size-now?\">¶</a></li><li><a href=\"#Q%3A-can-we-see-the-weights%3F\">V. Q: can we see the weights?</a><a class=\"anchor-link\" href=\"#Q:-can-we-see-the-weights?\">¶</a></li><li><a href=\"#Q%3A-How-does-this-Conv2d-change-an-image%3F\">VI. Q: How does this Conv2d change an image?</a><a class=\"anchor-link\" href=\"#Q:-How-does-this-Conv2d-change-an-image?\">¶</a></li><li><a href=\"#Q%3A-how-do-we-plot-the-output-as-image%3F\">VII. Q: how do we plot the output as image?</a><a class=\"anchor-link\" href=\"#Q:-how-do-we-plot-the-output-as-image?\">¶</a></li><li><a href=\"#Write-a-function-to-plot-n-output-filters.\">VIII. Write a function to plot n output filters.</a><a class=\"anchor-link\" href=\"#Write-a-function-to-plot-n-output-filters.\">¶</a></li><li><a href=\"#Q%3A-What-happens-if-we-increase-the-kernel-size%3F\">IX. Q: What happens if we increase the kernel size?</a><a class=\"anchor-link\" href=\"#Q:-What-happens-if-we-increase-the-kernel-size?\">¶</a></li><li><a href=\"#Q%3A-Can-we-choose-any-kernel-size%3F\">X. Q: Can we choose any kernel size?</a><a class=\"anchor-link\" href=\"#Q:-Can-we-choose-any-kernel-size?\">¶</a></li><li><a href=\"#Q%3A-What-if-we-change-strides-size%3F\">XI. Q: What if we change strides size?</a><a class=\"anchor-link\" href=\"#Q:-What-if-we-change-strides-size?\">¶</a></li><li><a href=\"#Q%3A-Is-it-beter-to-start-with-large-kernel-size-or-smaller%3F\">XII. Q: Is it beter to start with large kernel size or smaller?</a><a class=\"anchor-link\" href=\"#Q:-Is-it-beter-to-start-with-large-kernel-size-or-smaller?\">¶</a></li><li><a href=\"#Q%3A-What-if-we-add-activation-function%3F\">XIII. Q: What if we add activation function?</a><a class=\"anchor-link\" href=\"#Q:-What-if-we-add-activation-function?\">¶</a></li></ul><li><a href=\"#Pooling\">II. Pooling</a><a class=\"anchor-link\" href=\"#Pooling\">¶</a></li><ul class=\"toc\"><li><a href=\"#Let's-add-a-maxpooling-layer.\">I. Let's add a maxpooling layer.</a><a class=\"anchor-link\" href=\"#Let's-add-a-maxpooling-layer.\">¶</a></li><li><a href=\"#Q%3A-What-happens-if-we-change-pooling_size%3F\">II. Q: What happens if we change pooling_size?</a><a class=\"anchor-link\" href=\"#Q:-What-happens-if-we-change-pooling_size?\">¶</a></li></ul><li><a href=\"#Other-layers\">III. Other layers</a><a class=\"anchor-link\" href=\"#Other-layers\">¶</a></li><li><a href=\"#Q%3A-How-to-design-a-CNN%3F\">IV. Q: How to design a CNN?</a><a class=\"anchor-link\" href=\"#Q:-How-to-design-a-CNN?\">¶</a></li><ul class=\"toc\"><li><a href=\"#Q%3A-Can-we-visualize-layer-outputs%3F\">I. Q: Can we visualize layer outputs?</a><a class=\"anchor-link\" href=\"#Q:-Can-we-visualize-layer-outputs?\">¶</a></li></ul><li><a href=\"#Evaluation-of-model\">V. Evaluation of model</a><a class=\"anchor-link\" href=\"#Evaluation-of-model\">¶</a></li><ul class=\"toc\"><li><a href=\"#Example-of-Underfitting\">I. Example of Underfitting</a><a class=\"anchor-link\" href=\"#Example-of-Underfitting\">¶</a></li><li><a href=\"#Callbacks\">II. Callbacks</a><a class=\"anchor-link\" href=\"#Callbacks\">¶</a></li><li><a href=\"#Example-of-Overfitting\">III. Example of Overfitting</a><a class=\"anchor-link\" href=\"#Example-of-Overfitting\">¶</a></li><li><a href=\"#Regularization\">IV. Regularization</a><a class=\"anchor-link\" href=\"#Regularization\">¶</a></li><li><a href=\"#Early-Stopping\">V. Early Stopping</a><a class=\"anchor-link\" href=\"#Early-Stopping\">¶</a></li></ul><li><a href=\"#Model-Ensembling\">VI. Model Ensembling</a><a class=\"anchor-link\" href=\"#Model-Ensembling\">¶</a></li></ul></ul></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Momentum\n",
    "Several Optimizers\n",
    "<img src=\"http://upload-images.jianshu.io/upload_images/1667471-c92f34f4461025cd.gif\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "# import cv2\n",
    "from skimage import transform\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"/Users/shahab/Documents/kaggle/dogs_vs_cats\"\n",
    "img_list0 = os.listdir(data_path+\"/train/\")\n",
    "len(img_list0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels0 = [int(img.split('.')[0]=='cat') for img in img_list0]\n",
    "labels0[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_SAMPLE_IMAGES=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_SAMPLE_IMAGES:\n",
    "    n=100\n",
    "    cat_images = [img for img in img_list0[:100] if img.startswith(\"cat\")]\n",
    "    dog_images = [img for img in img_list0[-100:] if img.startswith(\"dog\")]\n",
    "    img_list=cat_images+dog_images\n",
    "    labels=labels0[:100]+labels0[-100:]\n",
    "else:\n",
    "    img_list=img_list0\n",
    "    labels-labels0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [mpimg.imread(data_path +'/train/'+ img) for img in img_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resized_images = [np.reshape(cv2.resize(img,(64,64),interpolation=cv2.INTER_AREA), [1,64,64,3]) for img in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_images = [np.reshape(skimage.transform.resize(img,(64,64)), [1,64,64,3]) for img in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!gpustat -cup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Convolution2D, MaxPooling2D, Dense, Activation\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(resized_images)*0.9)\n",
    "train_x = np.vstack(resized_images[:train_size])\n",
    "test_x = resized_images[train_size:]\n",
    "train_y = np.vstack(labels[:train_size])\n",
    "test_y = labels[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://keras.io/layers/convolutional/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look at a single Convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(filters=3, kernel_size=(4,4), strides=(1,1), \n",
    "                        padding='valid', input_shape=(64, 64, 3), activation=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: what's the output size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(N - F) / stride + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model.predict(train_x[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: Change padding parameter to 'same'. What's the output size now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: Change number of filters  to 10. What's the output size now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: can we see the weights? How many parameters (weights)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "w0=model.layers[0].weights[0].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(w0.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: How does this Conv2d change an image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take an image and send it to this Conv2d layer, and then look at the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=np.random.randint(len(train_x))\n",
    "sample_image=train_x[n:n+1] #conv2d expects an array of images. so we're taking an array of size 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sample_image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_filters=10\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(filters=n_filters, kernel_size=(4,4), strides=(1,1),\n",
    "                        padding='same', input_shape=(64, 64, 3), activation=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o=model.predict(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(o.ravel());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: how do we plot the output as image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can take one filter and plot as gray scale\n",
    "plt.imshow(o[0,:,:,0], cmap=plt.cm.gray)\n",
    "#or take 3 filters and plot as RGB image:\n",
    "# plt.imshow(o[0,:,:,:3])\n",
    "plt.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a function to plot n output filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_output(o, subplots=(2,5), cmap=plt.cm.gray):\n",
    "    n_plots=subplots[0]*subplots[1]\n",
    "    plt.figure(figsize=(subplots[1]*3, subplots[0]*3))\n",
    "    for i in range(min(n_filters,n_plots)):\n",
    "        plt.subplot(subplots[0],subplots[1],i+1)\n",
    "        plt.imshow(o[0,:,:,i], cmap=cmap)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the first 10 filters\n",
    "plot_output(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: What happens if we increase the kernel size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try (16,16), (32,32), (63,63), (100,100) with padding = 'same'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: Can we choose any kernel size? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try (10,5), (32,3), (100,3) with both padding 'valid' and 'same'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: What if we change strides size? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: Is it beter to start with large kernel size or smaller?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: What if we add activation function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://keras.io/activations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://keras.io/layers/pooling/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's add a maxpooling layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling2D, AveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_filters=10\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(filters=n_filters, kernel_size=(4,4), strides=(1,1),\n",
    "                        padding='same', input_shape=(64, 64, 3), activation=None))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "o=model.predict(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_output(o, subplots=(1,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: What happens if we change pooling_size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add final layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "o=model.predict(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(o.ravel());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(256, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o=model.predict(sample_image)\n",
    "\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o=model.predict(sample_image)\n",
    "\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "o=model.predict(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: How to design a CNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "typycal architecture:\n",
    "\n",
    "[(CONV-RELU)*N-POOL?]*M-(FC-RELU)*K,SOFTMAX\n",
    "\n",
    "where N is usually up to ~5, M is large, 0 <= K <= 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=1e-3)\n",
    "objective = 'binary_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convnet_v1():\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(32, kernel_size=(4,4), padding='same', input_shape=(64, 64, 3), activation='relu'))\n",
    "    model.add(Convolution2D(32, kernel_size=(4,4), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "    model.add(Convolution2D(64, kernel_size=(4,4), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "    \n",
    "    model.add(Convolution2D(128, kernel_size=(4,4), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "    \n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu',kernel_regularizer=regularizers.l2(0.3)))\n",
    "    \n",
    "    model.add(Dense(256, activation='relu',kernel_regularizer=regularizers.l2(0.3)))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss=objective, optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = convnet_v1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "o=model.predict(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: Can we visualize layer outputs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.keras.io/how-convolutional-neural-networks-see-the-world.html\n",
    "\n",
    "http://cs231n.github.io/understanding-cnn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of model\n",
    " - Train, validation and test\n",
    " - Learning curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Callbacks\n",
    "https://keras.io/callbacks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=1e-3)\n",
    "objective = 'binary_crossentropy'\n",
    "nb_epoch=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit(train_x, train_y, batch_size=32, epochs=nb_epoch,\n",
    "          validation_split=0.25, verbose=1, shuffle=True, callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.losses\n",
    "val_loss = history.val_losses\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Trend (Overfitting)')\n",
    "plt.plot(loss[1:], 'blue', label='Training Loss')\n",
    "plt.plot(val_loss[1:], 'green', label='Validation Loss')\n",
    "plt.xticks(range(0,nb_epoch)[0::2])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "History callback is automatically called. No need to pass it.\n",
    "You can save the output of model.fit in a history variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitting=model.fit(train_x, train_y, batch_size=32, epochs=nb_epoch,\n",
    "          validation_split=0.25, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitting.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fitting.history['loss'],'b')\n",
    "plt.plot(fitting.history['val_loss'],'g')\n",
    "plt.legend(('training_loss', 'testing_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of Overfitting\n",
    "It seems that we need a more complex model. Let's try Vgg-net.\n",
    "\n",
    "It is proved that a double conv with smaller kernel size ssuch as (3, 3), can cost less and be more conplex (because it use relu twice) than a single conv with a larger kernel size such as (5, 5). That's why Vgg perform so well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=1e-5)\n",
    "\n",
    "# VggNet-16\n",
    "def convnet_v2():\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(32, kernel_size=(3, 3), padding='same', input_shape=(64, 64, 3), activation='relu'))\n",
    "    model.add(Convolution2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Convolution2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Convolution2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Convolution2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Convolution2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Convolution2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss=objective, optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = convnet_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitting=model.fit(train_x, train_y, batch_size=32, epochs=10,\n",
    "          validation_split=0.25, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitting.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = fitting.history['loss']\n",
    "val_loss = fitting.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('VGG-16 Loss Trend (Overfitting)')\n",
    "plt.plot(loss, 'blue', label='Training Loss')\n",
    "plt.plot(val_loss, 'green', label='Validation Loss')\n",
    "plt.xticks(range(0,nb_epoch)[0::2])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To trade-off the overfitting, we use L2-regulerization, Dropout and Early stopping here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convnet_v3():\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(32, kernel_size=(3, 3), padding='same', input_shape=(64, 64, 3), activation='relu'))\n",
    "    model.add(Convolution2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Convolution2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Convolution2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Convolution2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Convolution2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(Convolution2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss=objective, optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = convnet_v3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Early Stopping\n",
    "https://keras.io/callbacks/#earlystopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "\n",
    "# history = LossHistory()\n",
    "fitting=model.fit(train_x, train_y, batch_size=32, epochs=20,\n",
    "          validation_split=0.25, verbose=1, shuffle=True, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = fitting.history['loss']\n",
    "val_loss = fitting.history['val_loss']\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('VGG-16 Loss Trend')\n",
    "plt.plot(loss, 'blue', label='Training Loss')\n",
    "plt.plot(val_loss, 'green', label='Validation Loss')\n",
    "#plt.xticks(range(0,nb_epoch)[0::2])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Ensembling\n",
    "Ensembing means to combine several weaker models to obtain a stronger model which can achieve better performance on both accuracy and overfitting. In machine learning, here are several ensembling methods:\n",
    " - Bagging (Random Forest)\n",
    " - Boosting (Adaboost, Xgboost)\n",
    " - Stacking\n",
    " - Majority voting / averaging\n",
    " \n",
    "In neural networks, we can also use ensembling to enhance the models performance. For instance, one way is to train several models separately (with different structure, hyperparameters, loss function, etc.) or even different snapshot of a single model in different epochs (https://arxiv.org/pdf/1704.00109.pdf). Another way is to combine several models on their hidden layers, where defferent models are used to extract different features, for example, the Amazon image tagging task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
